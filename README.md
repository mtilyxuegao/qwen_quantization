# Qwen3-4B-Instruct INT8 é‡åŒ–ä¸è¯„ä¼°

æœ¬é¡¹ç›®å®Œæˆ Qwen3-4B-Instruct-2507 æ¨¡å‹çš„ INT8 é‡åŒ–ã€éƒ¨ç½²å’Œè´¨é‡è¯„ä¼°ã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
qwen_quantization/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ quantize_model.py       # æ¨¡å‹é‡åŒ–è„šæœ¬
â”œâ”€â”€ run_gpqa_eval.py            # GPQA è¯„ä¼°è„šæœ¬
â”œâ”€â”€ simple-evals/               # OpenAI simple-evals ä»“åº“
â”œâ”€â”€ results/                    # è¯„ä¼°ç»“æœè¾“å‡ºç›®å½•
â”œâ”€â”€ system_info.md              # ç³»ç»Ÿé…ç½®ä¿¡æ¯
â””â”€â”€ README.md                   # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# 1. é‡åŒ–æ¨¡å‹
python scripts/quantize_model.py

# 2. å¯åŠ¨ sglangï¼ˆåŸå§‹æ¨¡å‹ï¼‰
python -m sglang.launch_server --model-path <æ¨¡å‹è·¯å¾„> --port 30000

# 3. æµ‹è¯•è¯„ä¼°ï¼ˆ10é¢˜ï¼‰
python run_gpqa_eval.py --model-name test --num-examples 10

# 4. å®Œæ•´è¯„ä¼°
python run_gpqa_eval.py --model-name qwen3-4b-original
```

---

## ğŸ“– å®Œæ•´æµç¨‹

### é˜¶æ®µ 1: æ¨¡å‹é‡åŒ–

ä½¿ç”¨ llmcompressor å°†æ¨¡å‹é‡åŒ–ä¸º INT8 (W8A8)ã€‚

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# è¿è¡Œé‡åŒ–è„šæœ¬ï¼ˆéœ€è¦ 30-60 åˆ†é’Ÿï¼‰
python scripts/quantize_model.py
```

**é‡åŒ–é…ç½®ï¼š**
- ç®—æ³•: SmoothQuant + GPTQ
- æ–¹æ¡ˆ: W8A8 (æƒé‡å’Œæ¿€æ´»å‡ä¸º INT8)
- æ ¡å‡†æ•°æ®: ultrachat_200k (512 æ ·æœ¬)
- è¾“å‡ºè·¯å¾„: `/data/jisenli2/huggingface/Qwen3-4B-Instruct-2507-INT8-W8A8`

---

### é˜¶æ®µ 2: éƒ¨ç½²æ¨ç†æœåŠ¡

ä½¿ç”¨ sglang éƒ¨ç½²æ¨¡å‹ï¼ˆæ”¯æŒ OpenAI å…¼å®¹ APIï¼‰ã€‚

#### åŸå§‹æ¨¡å‹

```bash
python -m sglang.launch_server \
  --model-path /data/jisenli2/huggingface/models--Qwen--Qwen3-4B-Instruct-2507/snapshots/cdbee75f17c01a7cc42f958dc650907174af0554 \
  --host 0.0.0.0 \
  --port 30000 \
  --context-length 262144
```

#### INT8 é‡åŒ–æ¨¡å‹

```bash
python -m sglang.launch_server \
  --model-path /data/jisenli2/huggingface/Qwen3-4B-Instruct-2507-INT8-W8A8 \
  --host 0.0.0.0 \
  --port 30000 \
  --context-length 262144
```

**æœåŠ¡ç«¯ç‚¹ï¼š** `http://127.0.0.1:30000/v1` (OpenAI å…¼å®¹)

---

### é˜¶æ®µ 3: é€Ÿåº¦è¯„ä¼°

ä½¿ç”¨ sglang è‡ªå¸¦çš„ benchmark å·¥å…·æµ‹è¯•ååé‡ã€‚

```bash
python -m sglang.bench_one_batch_server \
  --base-url http://127.0.0.1:30000 \
  --model-path Qwen/Qwen3-4B-Instruct-2507 \
  --batch-size 32 \
  --input-len 256 \
  --output-len 32
```

è®°å½•ä»¥ä¸‹æŒ‡æ ‡ï¼š
- **Throughput** (tokens/s)
- **Latency** (ms)
- **GPU Memory** (GB)

---

### é˜¶æ®µ 4: è´¨é‡è¯„ä¼° (GPQA)

ä½¿ç”¨ OpenAI Simple Evals çš„ GPQA benchmark æµ‹è¯•æ¨¡å‹å‡†ç¡®ç‡ã€‚

#### è¯„ä¼°åŸå§‹æ¨¡å‹

```bash
# ç¡®ä¿ sglang æœåŠ¡å™¨å·²å¯åŠ¨ï¼ˆåŸå§‹æ¨¡å‹ï¼‰

# å®Œæ•´è¯„ä¼°ï¼ˆ448é¢˜Ã—10æ¬¡ï¼‰
python run_gpqa_eval.py --model-name qwen3-4b-original

# æµ‹è¯•æ¨¡å¼ï¼ˆ10é¢˜Ã—10æ¬¡ï¼‰
python run_gpqa_eval.py --model-name qwen3-4b-original --num-examples 10
```

#### è¯„ä¼° INT8 æ¨¡å‹

```bash
# åœæ­¢åŸå§‹æ¨¡å‹æœåŠ¡å™¨ï¼Œå¯åŠ¨ INT8 æ¨¡å‹æœåŠ¡å™¨

# è¿è¡Œè¯„ä¼°
python run_gpqa_eval.py --model-name qwen3-4b-int8
```

#### å‘½ä»¤è¡Œå‚æ•°

```bash
--model-name     æ¨¡å‹åç§°ï¼ˆç”¨äºä¿å­˜ç»“æœï¼‰
--base-url       sglang æœåŠ¡å™¨åœ°å€ï¼ˆé»˜è®¤: http://127.0.0.1:30000/v1ï¼‰
--num-examples   é™åˆ¶æµ‹è¯•æ ·æœ¬æ•°ï¼ˆNone=å…¨éƒ¨ï¼‰
--n-repeats      é‡å¤è¯„ä¼°æ¬¡æ•°ï¼ˆé»˜è®¤: 10ï¼‰
--variant        GPQA å˜ä½“ï¼ˆé»˜è®¤: diamondï¼‰
--seed           éšæœºç§å­èµ·å§‹å€¼ï¼ˆé»˜è®¤: 1234ï¼‰
--max-tokens     æœ€å¤§è¾“å‡ºé•¿åº¦ï¼ˆé»˜è®¤: 4096ï¼‰
--output-dir     ç»“æœä¿å­˜ç›®å½•ï¼ˆé»˜è®¤: results/ï¼‰
```

**GPQA è¯´æ˜ï¼š**
- Diamond å˜ä½“ï¼š448 é“ç ”ç©¶ç”Ÿçº§åˆ«ç§‘å­¦é—®ç­”é¢˜
- é‡å¤è¯„ä¼°ï¼šå¤–å±‚å¾ªç¯ 10 æ¬¡ï¼Œæ¯æ¬¡ç‹¬ç«‹è¯„ä¼°æ‰€æœ‰é¢˜ç›®
- é¢„è®¡è€—æ—¶ï¼šæ¯æ¬¡çº¦ 1 å°æ—¶ï¼Œæ€»è®¡ 10 å°æ—¶
- å»ºè®®å…ˆç”¨ `--num-examples 10 --n-repeats 1` å¿«é€Ÿæµ‹è¯•
- **å¢é‡ä¿å­˜**ï¼šæ¯å®Œæˆä¸€éï¼ˆrepeatï¼‰ç«‹å³ä¿å­˜ï¼Œå¯æŸ¥çœ‹ä¸­é—´è¿›åº¦

---

## ğŸ“Š è¯„ä¼°å‚æ•°

### é‡‡æ ·å‚æ•°ï¼ˆç¡¬ç¼–ç ï¼‰
- Temperature: 0.7
- Top-P: 0.8
- Top-K: 20
- Min-P: 0.0
- Max Tokens: 4096ï¼ˆå¯é€šè¿‡ `--max-tokens` ä¿®æ”¹ï¼‰

### GPQA é…ç½®
- n_repeats: 10ï¼ˆå¤–å±‚å¾ªç¯æ¬¡æ•°ï¼‰
- variant: diamondï¼ˆå¯é€‰ï¼šdiamond, extended, mainï¼‰
- num_examples: Noneï¼ˆå…¨éƒ¨448é¢˜ï¼‰
- seed: 1234ï¼ˆæ¯æ¬¡æŸ¥è¯¢è‡ªåŠ¨é€’å¢ï¼‰

---

## ğŸ“ˆ ç»“æœæ–‡ä»¶

è¯„ä¼°å®Œæˆååœ¨ `results/` ç›®å½•ç”Ÿæˆï¼š

- `gpqa_{model}_repeat0.json` - ç¬¬1æ¬¡è¯„ä¼°ç»“æœ
- `gpqa_{model}_repeat1.json` - ç¬¬2æ¬¡è¯„ä¼°ç»“æœ
- ...
- `gpqa_{model}_repeat9.json` - ç¬¬10æ¬¡è¯„ä¼°ç»“æœ
- `gpqa_{model}_final.json` - æ±‡æ€»ç»Ÿè®¡ï¼ˆå‡å€¼ã€æ ‡å‡†å·®ï¼‰
- `gpqa_{model}.html` - HTML æŠ¥å‘Š

### æŒ‡æ ‡å¯¹æ¯”

```python
# è¯»å–æ±‡æ€»ç»“æœ
import json

with open('results/gpqa_qwen3-4b-original_final.json') as f:
    original = json.load(f)
    
with open('results/gpqa_qwen3-4b-int8_final.json') as f:
    int8 = json.load(f)

print(f"åŸå§‹æ¨¡å‹: {original['mean_score']:.4f} Â± {original['std_score']:.4f}")
print(f"INT8 æ¨¡å‹: {int8['mean_score']:.4f} Â± {int8['std_score']:.4f}")
print(f"å‡†ç¡®ç‡ä¸‹é™: {(original['mean_score'] - int8['mean_score']):.4f}")
```

---

## ğŸ–¥ï¸ ç³»ç»Ÿç¯å¢ƒ

- **GPU**: NVIDIA A100 80GB Ã— 8 (ä½¿ç”¨ 1 ä¸ª)
- **CPU**: Intel Xeon Platinum 8480+ (224 æ ¸)
- **å†…å­˜**: 2.0 TB
- **CUDA**: 12.1
- **Python**: 3.10.12

### å…³é”®ä¾èµ–
- llmcompressor==0.8.1
- vllm==0.11.0
- sglang==0.5.3.post3
- torch==2.8.0
- transformers==4.57.1

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **é‡åŒ–**: é¦–æ¬¡é‡åŒ–çº¦ 30-60 åˆ†é’Ÿï¼Œä¼šä¸‹è½½ ultrachat æ•°æ®é›†ï¼ˆ~1-2GBï¼‰

2. **æ˜¾å­˜**:
   - åŸå§‹æ¨¡å‹: ~8-10GB
   - INT8 æ¨¡å‹: ~4-6GB
   - é‡åŒ–è¿‡ç¨‹: ~15-20GB

3. **è¯„ä¼°**: å®Œæ•´è¯„ä¼°éœ€ 1-2 å°æ—¶ï¼Œå»ºè®®å…ˆç”¨ `--num-examples 10` æµ‹è¯•

4. **å¢é‡ä¿å­˜**: 
   - æ¯å®Œæˆä¸€éï¼ˆrepeatï¼‰ç«‹å³ä¿å­˜åˆ° `*_repeat{n}.json`
   - ä¸­æ–­åå·²å®Œæˆçš„ repeats ç»“æœä¿ç•™
   - å¯éšæ—¶æŸ¥çœ‹ä¸­é—´è¿›åº¦å’Œç»Ÿè®¡

5. **ä¾èµ–å†²çª**: å¦‚é‡ llmcompressor é”™è¯¯ï¼š
   ```bash
   pip install --upgrade compressed-tensors datasets
   ```

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [vLLM INT8 é‡åŒ–æ–‡æ¡£](https://docs.vllm.ai/en/latest/features/quantization/int8.html)
- [sglang æ–‡æ¡£](https://docs.sglang.ai/)
- [OpenAI Simple Evals](https://github.com/openai/simple-evals)
- [GPQA è®ºæ–‡](https://arxiv.org/abs/2311.12022)
- [Qwen3 æ¨¡å‹](https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507)

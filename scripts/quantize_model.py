#!/usr/bin/env python3
"""
é‡åŒ– Qwen3-4B-Instruct-2507 æ¨¡å‹åˆ° INT8
"""
import logging
import os
from datetime import datetime
from pathlib import Path

from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
from llmcompressor import oneshot  # ä¿®æ”¹ï¼šoneshot åœ¨é¡¶å±‚ï¼Œä¸åœ¨ transformers å­æ¨¡å—
from llmcompressor.modifiers.quantization import GPTQModifier

# é…ç½®
MODEL_ID = "Qwen/Qwen3-4B-Instruct-2507"
OUTPUT_DIR = "/data/jisenli2/huggingface/Qwen3-4B-Instruct-2507-INT8-W8A16"
LOG_DIR = "/home/jisenli2/qwen_quantization/logs"

NUM_CALIBRATION_SAMPLES = 512
MAX_SEQUENCE_LENGTH = 2048

# è®¾ç½®æ—¥å¿—
def setup_logger():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°"""
    # åˆ›å»º logs ç›®å½•
    os.makedirs(LOG_DIR, exist_ok=True)
    
    # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ—¥å¿—æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(LOG_DIR, f"quantize_{timestamp}.log")
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = '%(asctime)s - %(levelname)s - %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    
    # åˆ›å»º logger
    logger = logging.getLogger('quantization')
    logger.setLevel(logging.INFO)
    
    # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
    logger.handlers.clear()
    
    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(logging.Formatter(log_format, date_format))
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(logging.Formatter(log_format, date_format))
    
    # æ·»åŠ å¤„ç†å™¨
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    return logger

def main():
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    logger = setup_logger()
    
    logger.info("=" * 60)
    logger.info("æ­¥éª¤ 1/4: åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨")
    logger.info("=" * 60)
    
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_ID,
        device_map="auto",
        torch_dtype="auto",
    )
    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
    
    logger.info(f"âœ… æ¨¡å‹å·²åŠ è½½: {MODEL_ID}")
    logger.info(f"âœ… åˆ†è¯å™¨å·²åŠ è½½")
    
    logger.info("")
    logger.info("=" * 60)
    logger.info("æ­¥éª¤ 2/4: å‡†å¤‡æ ¡å‡†æ•°æ®")
    logger.info("=" * 60)
    
    # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†
    logger.info("æ­£åœ¨åŠ è½½æ•°æ®é›†...")
    ds = load_dataset("HuggingFaceH4/ultrachat_200k", split="train_sft")
    ds = ds.shuffle(seed=42).select(range(NUM_CALIBRATION_SAMPLES))
    logger.info(f"å·²åŠ è½½ {len(ds)} æ¡æ ·æœ¬")
    
    def preprocess(example):
        return {"text": tokenizer.apply_chat_template(example["messages"], tokenize=False)}
    
    logger.info("æ­£åœ¨é¢„å¤„ç†æ•°æ®...")
    ds = ds.map(preprocess, desc="é¢„å¤„ç†", num_proc=4)  # æ·»åŠ è¿›åº¦æ¡å’Œå¤šè¿›ç¨‹
    
    def tokenize(sample):
        return tokenizer(
            sample["text"], 
            padding=False, 
            max_length=MAX_SEQUENCE_LENGTH, 
            truncation=True, 
            add_special_tokens=False
        )
    
    logger.info("æ­£åœ¨åˆ†è¯...")
    ds = ds.map(tokenize, remove_columns=ds.column_names, desc="åˆ†è¯", num_proc=4)  # æ·»åŠ è¿›åº¦æ¡å’Œå¤šè¿›ç¨‹
    
    logger.info(f"âœ… æ ¡å‡†æ•°æ®å·²å‡†å¤‡: {NUM_CALIBRATION_SAMPLES} æ ·æœ¬")
    
    logger.info("")
    logger.info("=" * 60)
    logger.info("æ­¥éª¤ 3/4: åº”ç”¨ INT8 é‡åŒ– (W8A16)")
    logger.info("=" * 60)
    logger.info("â³ è¿™å¯èƒ½éœ€è¦ 30-60 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
    logger.info("")
    logger.info("é‡åŒ–é…ç½®:")
    logger.info("  - GPTQ: W8A16 (æƒé‡INT8, æ¿€æ´»FP16)")
    logger.info("  - å¿½ç•¥å±‚: lm_head")
    logger.info("  - æ ¡å‡†æ ·æœ¬: %d", NUM_CALIBRATION_SAMPLES)
    logger.info("")
    
    # é…ç½®é‡åŒ–ç®—æ³•
    recipe = [
        GPTQModifier(targets="Linear", scheme="W8A16", ignore=["lm_head"]),
    ]
    
    import time
    start_time = time.time()
    
    # åº”ç”¨é‡åŒ–ï¼ˆllmcompressor ä¼šè‡ªåŠ¨æ˜¾ç¤ºè¿›åº¦æ¡ï¼‰
    logger.info("å¼€å§‹é‡åŒ–...")
    oneshot(
        model=model,
        dataset=ds,
        recipe=recipe,
        max_seq_length=MAX_SEQUENCE_LENGTH,
        num_calibration_samples=NUM_CALIBRATION_SAMPLES,
    )
    
    elapsed_time = time.time() - start_time
    logger.info(f"âœ… é‡åŒ–å®Œæˆ (è€—æ—¶: {elapsed_time/60:.1f} åˆ†é’Ÿ)")
    
    logger.info("")
    logger.info("=" * 60)
    logger.info("æ­¥éª¤ 4/4: ä¿å­˜é‡åŒ–æ¨¡å‹")
    logger.info("=" * 60)
    
    model.save_pretrained(OUTPUT_DIR, save_compressed=True)
    tokenizer.save_pretrained(OUTPUT_DIR)
    
    logger.info(f"âœ… é‡åŒ–æ¨¡å‹å·²ä¿å­˜åˆ°: {OUTPUT_DIR}")
    logger.info("")
    logger.info("=" * 60)
    logger.info("ğŸ‰ é‡åŒ–æµç¨‹å®Œæˆ!")
    logger.info("=" * 60)
    logger.info(f"ğŸ“‚ åŸå§‹æ¨¡å‹: {MODEL_ID}")
    logger.info(f"ğŸ“‚ é‡åŒ–æ¨¡å‹: {OUTPUT_DIR}")
    logger.info(f"ğŸ“Š é‡åŒ–æ–¹æ¡ˆ: W8A16 (æƒé‡INT8, æ¿€æ´»FP16, A100å…¼å®¹)")

if __name__ == "__main__":
    main()

